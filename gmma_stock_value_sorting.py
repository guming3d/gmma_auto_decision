import streamlit as st
import akshare as ak
import pandas as pd
import plotly.graph_objects as go
import numpy as np
from datetime import datetime, timedelta
import time
from functools import lru_cache
import os
import json
import traceback
import logging

# Configure logging to print to stdout
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Set page layout to wide mode
st.set_page_config(
    page_title="Aè‚¡å¸‚å€¼å˜åŒ–æ’åºå™¨",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# App title and description
st.title("Aè‚¡å¸‚å€¼å˜åŒ–æ’åºå·¥å…·")
st.markdown("""
æ­¤åº”ç”¨ç¨‹åºä½¿ç”¨ akshare æ•°æ®åˆ†æä¸­å›½ A è‚¡å¸‚åœºè‚¡ç¥¨åœ¨æŒ‡å®šæ—¶é—´åŒºé—´å†…çš„æ€»å¸‚å€¼/æµé€šå¸‚å€¼å˜åŒ–ã€‚
å®ƒå¯ä»¥æ’åå‡ºæ€»å¸‚å€¼/æµé€šå¸‚å€¼å¢åŠ æœ€å¤šçš„å‰100åªè‚¡ç¥¨å’Œå‡å°‘æœ€å¤šçš„å‰100åªè‚¡ç¥¨ã€‚
""")

# Create cache directory if it doesn't exist
cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "cache")
os.makedirs(cache_dir, exist_ok=True)

# Cache for stock list to avoid repeated API calls
@st.cache_data(ttl=3600)  # Cache for 1 hour
def get_stock_list():
    """è·å–æ‰€æœ‰æ²ªæ·±Aè‚¡çš„ä»£ç å’Œåç§°"""
    try:
        stock_list_df = ak.stock_info_a_code_name()
        return stock_list_df
    except Exception as e:
        error_msg = f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}"
        logging.error(error_msg)
        logging.error(traceback.format_exc())
        st.error(error_msg)
        return pd.DataFrame(columns=['code', 'name'])

# Function to get historical market value data for a stock
def get_stock_market_value(symbol, start_date, end_date, silent=True):
    """è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç»™å®šæ—¥æœŸèŒƒå›´çš„å¸‚å€¼æ•°æ®"""
    try:
        # For akshare stock_zh_a_hist, the symbol should not have sh/sz prefix
        symbol_no_prefix = symbol
        if symbol.startswith('sh') or symbol.startswith('sz'):
            symbol_no_prefix = symbol[2:]

        print("checking stock with symbol:", symbol)
        
            
        # Use the standard AkShare history function that includes market value data
        hist_df = ak.stock_zh_a_hist(symbol=symbol_no_prefix, period="daily", 
                                  start_date=start_date, end_date=end_date, adjust="")
        
        print(hist_df.head())
        if hist_df.empty:
            return None
        
        # Check if required columns exist - rename columns from Chinese to standardized names
        if 'æµé€šå¸‚å€¼' not in hist_df.columns or 'æ€»å¸‚å€¼' not in hist_df.columns:
            # Try to find alternative columns that might contain market value data
            market_value_columns = [col for col in hist_df.columns if 'å¸‚å€¼' in col]
            if market_value_columns and not silent:
                # Only log once for debugging, not for every stock
                if symbol_no_prefix in ['000001', '600000']:
                    st.warning(f"è‚¡ç¥¨ {symbol} æ•°æ®åˆ—åç§°ä¸æ ‡å‡†ï¼Œæ‰¾åˆ°å¯èƒ½çš„å¸‚å€¼åˆ—: {market_value_columns}")
            
            # Try to use stock_zh_a_hist with different parameters or approach
            try:
                # Try to get historical market data using a different approach
                start_date_obj = datetime.strptime(start_date, '%Y%m%d')
                end_date_obj = datetime.strptime(end_date, '%Y%m%d')
                
                # Try with individual dates to get day-specific data
                start_hist = ak.stock_zh_a_hist(symbol=symbol_no_prefix, period="daily",
                                         start_date=start_date, end_date=start_date, adjust="")
                end_hist = ak.stock_zh_a_hist(symbol=symbol_no_prefix, period="daily",
                                       start_date=end_date, end_date=end_date, adjust="")
                
                # Check if we got market value data in either query
                if (not start_hist.empty and not end_hist.empty and 
                    'æµé€šå¸‚å€¼' in start_hist.columns and 'æ€»å¸‚å€¼' in start_hist.columns and
                    'æµé€šå¸‚å€¼' in end_hist.columns and 'æ€»å¸‚å€¼' in end_hist.columns):
                    
                    # Combine the data
                    combined_df = pd.concat([start_hist, end_hist])
                    return combined_df[['æ—¥æœŸ', 'åç§°', 'æµé€šå¸‚å€¼', 'æ€»å¸‚å€¼']]
                
                # If still no market value data, return None instead of using current data
                if not silent:
                    error_msg = f"æ— æ³•è·å–è‚¡ç¥¨ {symbol} çš„å†å²å¸‚å€¼æ•°æ®"
                    st.warning(error_msg)
                    logging.warning(error_msg)
                return None
                
            except Exception as e:
                if not silent:
                    error_msg = f"å°è¯•è·å– {symbol} å¸‚å€¼æ•°æ®çš„å¤‡é€‰æ–¹æ³•å¤±è´¥: {str(e)}"
                    st.warning(error_msg)
                    logging.warning(error_msg)
                    logging.debug(traceback.format_exc())
                return None
        
        # If we have the correct columns, return them
        return hist_df[['æ—¥æœŸ', 'åç§°', 'æµé€šå¸‚å€¼', 'æ€»å¸‚å€¼']]
    except Exception as e:
        if not silent:
            error_msg = f"è·å– {symbol} æ•°æ®å¤±è´¥: {str(e)}"
            st.warning(error_msg)
            logging.warning(error_msg)
            logging.debug(traceback.format_exc())
        return None

# Function to test available AkShare functions for historical data
def test_available_history_functions():
    """æµ‹è¯•å¯ç”¨çš„å†å²æ•°æ®å‡½æ•°"""
    test_stock = "000001"  # å¹³å®‰é“¶è¡Œ
    results = {}
    
    # List of potential functions to try
    functions_to_try = [
        {"name": "stock_zh_a_hist", "params": {"symbol": test_stock, "period": "daily", "start_date": "20230101", "end_date": "20230102", "adjust": ""}},
        {"name": "stock_zh_a_daily", "params": {"symbol": test_stock}},
        {"name": "stock_zh_a_spot_em", "params": {}},
        {"name": "stock_individual_info_em", "params": {"symbol": test_stock}}
    ]
    
    for func in functions_to_try:
        try:
            function_name = func["name"]
            function = getattr(ak, function_name)
            result = function(**func["params"])
            
            if not result.empty:
                # Check if market value data is available
                has_market_value = any('å¸‚å€¼' in col for col in result.columns)
                columns = list(result.columns)
                
                results[function_name] = {
                    "status": "success",
                    "has_market_value": has_market_value,
                    "columns": columns,
                    "sample": result.head(1).to_dict('records')[0] if not result.empty else {}
                }
            else:
                results[function_name] = {
                    "status": "empty_result",
                    "has_market_value": False,
                    "columns": []
                }
        except Exception as e:
            results[function_name] = {
                "status": "error",
                "error": str(e)
            }
    
    return results

# Function to add exchange prefix to stock code
def add_exchange_prefix(code):
    """æ ¹æ®è‚¡ç¥¨ä»£ç æ·»åŠ äº¤æ˜“æ‰€å‰ç¼€"""
    code = str(code).zfill(6)
    if code.startswith(('6', '688', '900')):
        return f"sh{code}"
    else:
        return f"sz{code}"

# Function to get market value for specific dates
def get_market_value_for_dates(symbol, start_date, end_date, silent=True):
    """è·å–æŒ‡å®šè‚¡ç¥¨åœ¨èµ·å§‹æ—¥å’Œç»“æŸæ—¥çš„å¸‚å€¼æ•°æ®"""
    try:
        # Get all data in range
        df = get_stock_market_value(symbol, start_date, end_date, silent)
        
        # Check if dataframe is None or empty
        if df is None:
            logging.warning(f"è‚¡ç¥¨ {symbol}: è·å–æ•°æ®è¿”å›ä¸º None")
            return None, None, None, None, None
        
        if df.empty:
            logging.warning(f"è‚¡ç¥¨ {symbol}: è·å–çš„æ•°æ®ä¸ºç©º DataFrame")
            return None, None, None, None, None
        
        # Log the DataFrame columns and first row for debugging
        logging.debug(f"è‚¡ç¥¨ {symbol} æ•°æ®åˆ—: {list(df.columns)}")
        logging.debug(f"è‚¡ç¥¨ {symbol} é¦–è¡Œæ•°æ®: {df.iloc[0].to_dict() if len(df) > 0 else 'No data'}")
        
        # Check required columns
        required_columns = ['æ—¥æœŸ', 'åç§°', 'æµé€šå¸‚å€¼', 'æ€»å¸‚å€¼']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logging.warning(f"è‚¡ç¥¨ {symbol}: ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}")
            return None, None, None, None, None
        
        # Convert date to datetime for comparison
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        
        # Ensure we have at least one record
        if len(df) < 1:
            logging.warning(f"è‚¡ç¥¨ {symbol}: æ•°æ®è¡Œæ•°ä¸º0")
            return None, None, None, None, None
        
        # Get start date record (first available)
        start_record = df.iloc[0]
        
        # Ensure we have at least two different days of data
        if len(df) < 2 and start_date != end_date:
            # If we only have one record but requested a range, use that record for both start and end
            logging.info(f"è‚¡ç¥¨ {symbol}: åªæœ‰ä¸€å¤©çš„æ•°æ®ï¼Œæ—¥æœŸä¸º {start_record['æ—¥æœŸ']}")
            end_record = start_record
        else:
            end_record = df.iloc[-1]
        
        # Log actual dates we're using for debugging
        logging.debug(f"è‚¡ç¥¨ {symbol}: ä½¿ç”¨å¼€å§‹æ—¥æœŸ {start_record['æ—¥æœŸ']} å’Œç»“æŸæ—¥æœŸ {end_record['æ—¥æœŸ']}")
        
        # Extract values - ensure numeric values
        try:
            # Check individual values
            
            # Check name
            name = start_record['åç§°']
            if pd.isna(name) or name == '':
                logging.warning(f"è‚¡ç¥¨ {symbol}: åç§°ä¸ºç©º")
                return None, None, None, None, None
                
            # Check market values - convert to numeric and check for NaN
            try:
                start_circ_mv = pd.to_numeric(start_record['æµé€šå¸‚å€¼'], errors='coerce')
                if pd.isna(start_circ_mv):
                    logging.warning(f"è‚¡ç¥¨ {symbol}: å¼€å§‹æ—¥æœŸçš„æµé€šå¸‚å€¼ä¸ºNaNæˆ–æ— æ³•è½¬æ¢ä¸ºæ•°å€¼")
                    return None, None, None, None, None
            except Exception as e:
                logging.warning(f"è‚¡ç¥¨ {symbol}: è½¬æ¢å¼€å§‹æ—¥æœŸæµé€šå¸‚å€¼æ—¶å‡ºé”™: {str(e)}")
                return None, None, None, None, None
                
            try:
                end_circ_mv = pd.to_numeric(end_record['æµé€šå¸‚å€¼'], errors='coerce')
                if pd.isna(end_circ_mv):
                    logging.warning(f"è‚¡ç¥¨ {symbol}: ç»“æŸæ—¥æœŸçš„æµé€šå¸‚å€¼ä¸ºNaNæˆ–æ— æ³•è½¬æ¢ä¸ºæ•°å€¼")
                    return None, None, None, None, None
            except Exception as e:
                logging.warning(f"è‚¡ç¥¨ {symbol}: è½¬æ¢ç»“æŸæ—¥æœŸæµé€šå¸‚å€¼æ—¶å‡ºé”™: {str(e)}")
                return None, None, None, None, None
                
            try:
                start_total_mv = pd.to_numeric(start_record['æ€»å¸‚å€¼'], errors='coerce')
                if pd.isna(start_total_mv):
                    logging.warning(f"è‚¡ç¥¨ {symbol}: å¼€å§‹æ—¥æœŸçš„æ€»å¸‚å€¼ä¸ºNaNæˆ–æ— æ³•è½¬æ¢ä¸ºæ•°å€¼")
                    return None, None, None, None, None
            except Exception as e:
                logging.warning(f"è‚¡ç¥¨ {symbol}: è½¬æ¢å¼€å§‹æ—¥æœŸæ€»å¸‚å€¼æ—¶å‡ºé”™: {str(e)}")
                return None, None, None, None, None
                
            try:
                end_total_mv = pd.to_numeric(end_record['æ€»å¸‚å€¼'], errors='coerce')
                if pd.isna(end_total_mv):
                    logging.warning(f"è‚¡ç¥¨ {symbol}: ç»“æŸæ—¥æœŸçš„æ€»å¸‚å€¼ä¸ºNaNæˆ–æ— æ³•è½¬æ¢ä¸ºæ•°å€¼")
                    return None, None, None, None, None
            except Exception as e:
                logging.warning(f"è‚¡ç¥¨ {symbol}: è½¬æ¢ç»“æŸæ—¥æœŸæ€»å¸‚å€¼æ—¶å‡ºé”™: {str(e)}")
                return None, None, None, None, None
            
            # Log successful market value extractions for debugging
            logging.debug(f"è‚¡ç¥¨ {symbol} - æˆåŠŸè·å–å¸‚å€¼æ•°æ®:")
            logging.debug(f"  å¼€å§‹æ—¥æœŸæµé€šå¸‚å€¼: {start_circ_mv}")
            logging.debug(f"  ç»“æŸæ—¥æœŸæµé€šå¸‚å€¼: {end_circ_mv}")
            logging.debug(f"  å¼€å§‹æ—¥æœŸæ€»å¸‚å€¼: {start_total_mv}")
            logging.debug(f"  ç»“æŸæ—¥æœŸæ€»å¸‚å€¼: {end_total_mv}")
                
            return name, start_circ_mv, end_circ_mv, start_total_mv, end_total_mv
        except KeyError as e:
            logging.warning(f"è‚¡ç¥¨ {symbol}: ç¼ºå°‘æ•°æ®åˆ— {str(e)}")
            return None, None, None, None, None
        except TypeError as e:
            logging.warning(f"è‚¡ç¥¨ {symbol}: ç±»å‹é”™è¯¯ {str(e)}")
            return None, None, None, None, None
    except Exception as e:
        logging.error(f"è‚¡ç¥¨ {symbol}: è·å–å¸‚å€¼æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        logging.error(traceback.format_exc())
        return None, None, None, None, None

# Function to calculate date range formatted for API
def get_formatted_date_range(days_ago):
    """è®¡ç®—ä»å½“å‰æ—¥æœŸå‘å‰æ¨ç®—çš„æ—¥æœŸï¼Œæ ¼å¼åŒ–ä¸ºAPIæ‰€éœ€æ ¼å¼"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days_ago)
    
    # Format dates to YYYYMMDD
    start_date_str = start_date.strftime('%Y%m%d')
    end_date_str = end_date.strftime('%Y%m%d')
    
    return start_date_str, end_date_str

# Function to test API with a single stock
def test_api_connectivity(start_date_str, end_date_str):
    """æµ‹è¯•ä¸APIçš„è¿æ¥å’Œæ•°æ®è·å–"""
    test_stocks = ['000001', '600000']  # Test with both SZ and SH markets
    results = []
    
    logging.info(f"å¼€å§‹æµ‹è¯•APIè¿æ¥ï¼Œä½¿ç”¨æ—¥æœŸèŒƒå›´: {start_date_str} è‡³ {end_date_str}")
    
    # First, test which functions are available
    function_test_results = test_available_history_functions()
    
    # Now test actual data retrieval for specific stocks
    for stock in test_stocks:
        try:
            symbol = add_exchange_prefix(stock)
            hist_df = get_stock_market_value(stock, start_date_str, end_date_str)
            
            if hist_df is not None and not hist_df.empty:
                sample_data = hist_df.head(1).to_dict('records')[0]
                results.append({
                    'stock': stock,
                    'status': 'success',
                    'columns': list(hist_df.columns),
                    'sample': sample_data
                })
            else:
                results.append({
                    'stock': stock,
                    'status': 'empty_response',
                    'columns': [],
                    'sample': {}
                })
        except Exception as e:
            error_msg = f"è·å– {stock} æ•°æ®æµ‹è¯•å¤±è´¥: {str(e)}"
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            results.append({
                'stock': stock,
                'status': 'error',
                'error': str(e),
                'traceback': traceback.format_exc()
            })
    
    return {
        'stock_tests': results,
        'function_tests': function_test_results
    }

# Main functionality
def main():
    # Sidebar options
    st.sidebar.title("åˆ†æè®¾ç½®")
    
    # Date range selection
    st.sidebar.subheader("æ—¶é—´åŒºé—´")
    date_range_option = st.sidebar.radio(
        "é€‰æ‹©æ—¶é—´åŒºé—´",
        ["è¿‡å»7å¤©", "è¿‡å»14å¤©", "è¿‡å»30å¤©", "è¿‡å»90å¤©", "è¿‡å»180å¤©", "è¿‡å»365å¤©", "è‡ªå®šä¹‰"]
    )
    
    # Handle date range selection
    if date_range_option == "è‡ªå®šä¹‰":
        today = datetime.now()
        default_start = today - timedelta(days=30)
        
        start_date = st.sidebar.date_input(
            "å¼€å§‹æ—¥æœŸ",
            value=default_start,
            max_value=today - timedelta(days=1)
        )
        
        end_date = st.sidebar.date_input(
            "ç»“æŸæ—¥æœŸ",
            value=today,
            min_value=start_date,
            max_value=today
        )
        
        # Format dates for API
        start_date_str = start_date.strftime('%Y%m%d')
        end_date_str = end_date.strftime('%Y%m%d')
    else:
        # Calculate days based on selection
        days_map = {
            "è¿‡å»7å¤©": 7,
            "è¿‡å»14å¤©": 14,
            "è¿‡å»30å¤©": 30,
            "è¿‡å»90å¤©": 90,
            "è¿‡å»180å¤©": 180,
            "è¿‡å»365å¤©": 365
        }
        days_ago = days_map[date_range_option]
        start_date_str, end_date_str = get_formatted_date_range(days_ago)
    
    # Market value type selection
    market_value_type = st.sidebar.radio(
        "é€‰æ‹©å¸‚å€¼ç±»å‹",
        ["æµé€šå¸‚å€¼", "æ€»å¸‚å€¼"]
    )
    
    # Number of stocks to display
    top_n = st.sidebar.slider(
        "æ˜¾ç¤ºæ¯ç»„å‰Nåªè‚¡ç¥¨",
        min_value=10,
        max_value=500,
        value=100,
        step=10
    )
    
    # Number of stocks to process
    process_limit = st.sidebar.slider(
        "å¤„ç†è‚¡ç¥¨æ•°é‡é™åˆ¶",
        min_value=100,
        max_value=5500,
        value=300,
        step=100,
        help="é™åˆ¶å¤„ç†çš„è‚¡ç¥¨æ•°é‡ï¼Œæ•°å€¼è¶Šå°å¤„ç†è¶Šå¿«ï¼Œè®¾ä¸ºæœ€å¤§å€¼å°†å¤„ç†æ‰€æœ‰è‚¡ç¥¨"
    )
    
    # Add a test API button
    if st.sidebar.button("æµ‹è¯•APIè¿æ¥", help="ç‚¹å‡»æµ‹è¯•ä¸APIçš„è¿æ¥çŠ¶æ€"):
        with st.spinner("æ­£åœ¨æµ‹è¯•APIè¿æ¥å’Œå¯ç”¨å‡½æ•°..."):
            try:
                api_test_results = test_api_connectivity(start_date_str, end_date_str)
                
                st.subheader("APIå‡½æ•°æµ‹è¯•ç»“æœ")
                for func_name, result in api_test_results['function_tests'].items():
                    if result['status'] == 'success':
                        market_value_status = "åŒ…å«" if result.get('has_market_value', False) else "ä¸åŒ…å«"
                        st.success(f"å‡½æ•° {func_name} è°ƒç”¨æˆåŠŸï¼Œ{market_value_status}å¸‚å€¼æ•°æ®")
                        st.write(f"å¯ç”¨åˆ—: {', '.join(result.get('columns', []))}")
                        if 'sample' in result:
                            with st.expander(f"{func_name} æ•°æ®æ ·ä¾‹"):
                                st.write(result['sample'])
                    else:
                        st.error(f"å‡½æ•° {func_name} è°ƒç”¨å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                st.subheader("è‚¡ç¥¨æ•°æ®æµ‹è¯•ç»“æœ")
                for result in api_test_results['stock_tests']:
                    if result['status'] == 'success':
                        st.success(f"æˆåŠŸè·å– {result['stock']} çš„æ•°æ®")
                        st.write(f"å¯ç”¨åˆ—: {', '.join(result['columns'])}")
                        with st.expander("æ•°æ®æ ·ä¾‹"):
                            st.write(result['sample'])
                    else:
                        st.error(f"è·å– {result['stock']} çš„æ•°æ®å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        if 'traceback' in result:
                            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                st.code(result['traceback'])
            except Exception as e:
                error_msg = f"æµ‹è¯•APIè¿æ¥æ—¶å‡ºé”™: {str(e)}"
                st.error(error_msg)
                logging.error(error_msg)
                logging.error(traceback.format_exc())
                st.code(traceback.format_exc())
    
    # Start analysis button
    if st.sidebar.button("å¼€å§‹åˆ†æ", type="primary"):
        try:
            # Display selected parameters
            st.subheader("åˆ†æå‚æ•°")
            st.write(f"- æ—¶é—´åŒºé—´: {start_date_str} è‡³ {end_date_str}")
            st.write(f"- å¸‚å€¼ç±»å‹: {market_value_type}")
            st.write(f"- æ˜¾ç¤ºæ¯ç»„å‰: {top_n} åªè‚¡ç¥¨")
            
            # Get stock list
            with st.spinner("æ­£åœ¨è·å– A è‚¡è‚¡ç¥¨åˆ—è¡¨..."):
                stock_list_df = get_stock_list()
                if stock_list_df.empty:
                    st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·ç¨åé‡è¯•")
                    return
                
                # Limit to first 300 stocks for faster processing
                original_count = len(stock_list_df)
                limit_count = process_limit  # Use the value from UI slider
                stock_list_df = stock_list_df.head(limit_count)
                st.success(f"å…±è·å–åˆ° {original_count} åª A è‚¡è‚¡ç¥¨ï¼Œå°†å¤„ç†å‰ {limit_count} åªè¿›è¡Œåˆ†æ")
            
            # Initialize results dataframe
            results = []
            
            # Create progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Create container for detailed error logs
            error_log_container = st.container()
            with error_log_container:
                error_expander = st.expander("é”™è¯¯æ—¥å¿— (å±•å¼€æŸ¥çœ‹è¯¦æƒ…)", expanded=False)
            
            # Process each stock
            total_stocks = len(stock_list_df)
            processed = 0
            errors = 0
            error_logs = []
            
            # Track timing for estimation
            start_time = time.time()
            time_estimates = []
            
            # Use batch processing to improve performance
            batch_size = 10  # Process stocks in batches of 10
            
            # Create a placeholder for batch progress
            batch_status = st.empty()
            estimate_text = st.empty()
            
            # Process stocks in batches
            for batch_start in range(0, total_stocks, batch_size):
                batch_start_time = time.time()
                batch_end = min(batch_start + batch_size, total_stocks)
                batch_status.text(f"å¤„ç†æ‰¹æ¬¡ {batch_start//batch_size + 1}/{(total_stocks + batch_size - 1)//batch_size}")
                
                # Get current batch of stocks
                batch_stocks = stock_list_df.iloc[batch_start:batch_end]
                
                for _, row in batch_stocks.iterrows():
                    try:
                        # Update progress
                        processed += 1
                        if processed % 5 == 0:
                            progress_bar.progress(min(processed / total_stocks, 1.0))
                            
                            # Calculate time estimate
                            elapsed_time = time.time() - start_time
                            stocks_per_second = processed / elapsed_time if elapsed_time > 0 else 0
                            remaining_stocks = total_stocks - processed
                            estimated_remaining_seconds = remaining_stocks / stocks_per_second if stocks_per_second > 0 else 0
                            
                            # Format time estimate
                            if estimated_remaining_seconds < 60:
                                time_estimate = f"çº¦ {int(estimated_remaining_seconds)} ç§’"
                            elif estimated_remaining_seconds < 3600:
                                time_estimate = f"çº¦ {int(estimated_remaining_seconds / 60)} åˆ†é’Ÿ"
                            else:
                                time_estimate = f"çº¦ {int(estimated_remaining_seconds / 3600)} å°æ—¶ {int((estimated_remaining_seconds % 3600) / 60)} åˆ†é’Ÿ"
                            
                            status_text.text(f"å·²å¤„ç†: {processed}/{total_stocks} (é”™è¯¯: {errors}) - æ¯è‚¡å¹³å‡ç”¨æ—¶: {elapsed_time/processed:.2f}ç§’")
                            estimate_text.text(f"é¢„è®¡å‰©ä½™æ—¶é—´: {time_estimate}")
                        
                        # Get stock code
                        code = str(row['code']).zfill(6)
                        
                        # Get market value data
                        name, start_circ_mv, end_circ_mv, start_total_mv, end_total_mv = get_market_value_for_dates(
                            code, start_date_str, end_date_str, silent=True
                        )
                        
                        # Skip if data is missing
                        if None in (name, start_circ_mv, end_circ_mv, start_total_mv, end_total_mv):
                            errors += 1
                            # Add to error log
                            if name is None:
                                name = row.get('name', 'æœªçŸ¥')
                            error_detail = f"è‚¡ç¥¨ {code} ({name}): æ•°æ®ä¸å®Œæ•´æˆ–ç¼ºå¤±"
                            error_logs.append(error_detail)
                            continue
                        
                        # Calculate changes
                        circ_mv_change = end_circ_mv - start_circ_mv
                        total_mv_change = end_total_mv - start_total_mv
                        
                        # Use try-except for percentage calculations to handle division by zero
                        try:
                            circ_mv_change_percent = (circ_mv_change / start_circ_mv * 100) if start_circ_mv > 0 else 0
                        except:
                            circ_mv_change_percent = 0
                            
                        try:
                            total_mv_change_percent = (total_mv_change / start_total_mv * 100) if start_total_mv > 0 else 0
                        except:
                            total_mv_change_percent = 0
                        
                        # Add to results
                        results.append({
                            'code': code,
                            'name': name,
                            'start_circ_mv': start_circ_mv,
                            'end_circ_mv': end_circ_mv,
                            'circ_mv_change': circ_mv_change,
                            'circ_mv_change_percent': circ_mv_change_percent,
                            'start_total_mv': start_total_mv,
                            'end_total_mv': end_total_mv,
                            'total_mv_change': total_mv_change,
                            'total_mv_change_percent': total_mv_change_percent
                        })
                    except Exception as e:
                        errors += 1
                        # Add to error log with more details
                        code = str(row['code']).zfill(6) if 'code' in row else 'unknown'
                        name = row.get('name', 'æœªçŸ¥')
                        error_detail = f"è‚¡ç¥¨ {code} ({name}): {str(e)}"
                        error_logs.append(error_detail)
                        logging.error(error_detail)
                        logging.debug(traceback.format_exc())
                        continue
                
                # Add a small delay between batches to prevent API rate limiting
                time.sleep(0.5)
            
            # Clear batch status
            batch_status.empty()
            
            # Update error log in UI
            with error_expander:
                if error_logs:
                    st.write(f"å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ° {len(error_logs)} ä¸ªé”™è¯¯:")
                    for i, log in enumerate(error_logs[:100]):  # Limit to first 100 errors
                        st.text(f"{i+1}. {log}")
                    if len(error_logs) > 100:
                        st.text(f"... è¿˜æœ‰ {len(error_logs) - 100} ä¸ªé”™è¯¯æœªæ˜¾ç¤º")
                else:
                    st.write("å¤„ç†è¿‡ç¨‹æœªå‘ç°é”™è¯¯")
            
            # Complete progress
            progress_bar.progress(1.0)
            status_text.text(f"åˆ†æå®Œæˆ! æ€»å…±å¤„ç†: {processed}/{total_stocks} (é”™è¯¯: {errors})")
            
            # Convert results to DataFrame
            if not results:
                st.error("æœªèƒ½è·å–æœ‰æ•ˆæ•°æ®ï¼Œè¯·å°è¯•å…¶ä»–æ—¶é—´åŒºé—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
                return
                
            results_df = pd.DataFrame(results)
            
            # Show summary of data collected
            st.info(f"æˆåŠŸæ”¶é›†äº† {len(results_df)} åªè‚¡ç¥¨çš„å¸‚å€¼æ•°æ®")
            
            # Determine which columns to use based on selected market value type
            if market_value_type == "æµé€šå¸‚å€¼":
                value_col = 'circ_mv_change'
                percent_col = 'circ_mv_change_percent'
                start_col = 'start_circ_mv'
                end_col = 'end_circ_mv'
            else:  # "æ€»å¸‚å€¼"
                value_col = 'total_mv_change'
                percent_col = 'total_mv_change_percent'
                start_col = 'start_total_mv'
                end_col = 'end_total_mv'
            
            # Sort for top increasing
            top_increase = results_df.sort_values(by=value_col, ascending=False).head(top_n).copy()
            
            # Sort for top decreasing
            top_decrease = results_df.sort_values(by=value_col, ascending=True).head(top_n).copy()
            
            # Format numbers for display (convert to äº¿å…ƒ)
            for df in [top_increase, top_decrease]:
                df['start_value_äº¿'] = df[start_col] / 100000000
                df['end_value_äº¿'] = df[end_col] / 100000000
                df['change_value_äº¿'] = df[value_col] / 100000000
                df['change_percent'] = df[percent_col]
            
            # Display top increasing stocks
            st.subheader(f"{market_value_type}å¢åŠ æœ€å¤šçš„å‰{top_n}åªè‚¡ç¥¨")
            
            # Format the display columns
            display_increase = top_increase[['code', 'name', 'start_value_äº¿', 'end_value_äº¿', 'change_value_äº¿', 'change_percent']].copy()
            display_increase.columns = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', f'èµ·å§‹{market_value_type}(äº¿å…ƒ)', f'ç»“æŸ{market_value_type}(äº¿å…ƒ)', 
                                        f'{market_value_type}å˜åŒ–(äº¿å…ƒ)', 'å˜åŒ–ç™¾åˆ†æ¯”(%)']
            
            # Format decimal places
            display_increase[f'èµ·å§‹{market_value_type}(äº¿å…ƒ)'] = display_increase[f'èµ·å§‹{market_value_type}(äº¿å…ƒ)'].round(2)
            display_increase[f'ç»“æŸ{market_value_type}(äº¿å…ƒ)'] = display_increase[f'ç»“æŸ{market_value_type}(äº¿å…ƒ)'].round(2)
            display_increase[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'] = display_increase[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'].round(2)
            display_increase['å˜åŒ–ç™¾åˆ†æ¯”(%)'] = display_increase['å˜åŒ–ç™¾åˆ†æ¯”(%)'].round(2)
            
            st.dataframe(display_increase, use_container_width=True)
            
            # Create bar chart for top increases
            fig_increase = go.Figure()
            fig_increase.add_trace(go.Bar(
                x=display_increase['è‚¡ç¥¨åç§°'],
                y=display_increase[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'],
                marker_color='red',
                text=display_increase[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'].round(2),
                textposition='auto'
            ))
            fig_increase.update_layout(
                title=f"{market_value_type}å¢åŠ æœ€å¤šçš„å‰{top_n}åªè‚¡ç¥¨",
                xaxis_title="è‚¡ç¥¨åç§°",
                yaxis_title=f"{market_value_type}å˜åŒ– (äº¿å…ƒ)",
                height=600
            )
            st.plotly_chart(fig_increase, use_container_width=True)
            
            # Display top decreasing stocks
            st.subheader(f"{market_value_type}å‡å°‘æœ€å¤šçš„å‰{top_n}åªè‚¡ç¥¨")
            
            # Format the display columns
            display_decrease = top_decrease[['code', 'name', 'start_value_äº¿', 'end_value_äº¿', 'change_value_äº¿', 'change_percent']].copy()
            display_decrease.columns = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', f'èµ·å§‹{market_value_type}(äº¿å…ƒ)', f'ç»“æŸ{market_value_type}(äº¿å…ƒ)', 
                                        f'{market_value_type}å˜åŒ–(äº¿å…ƒ)', 'å˜åŒ–ç™¾åˆ†æ¯”(%)']
            
            # Format decimal places
            display_decrease[f'èµ·å§‹{market_value_type}(äº¿å…ƒ)'] = display_decrease[f'èµ·å§‹{market_value_type}(äº¿å…ƒ)'].round(2)
            display_decrease[f'ç»“æŸ{market_value_type}(äº¿å…ƒ)'] = display_decrease[f'ç»“æŸ{market_value_type}(äº¿å…ƒ)'].round(2)
            display_decrease[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'] = display_decrease[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'].round(2)
            display_decrease['å˜åŒ–ç™¾åˆ†æ¯”(%)'] = display_decrease['å˜åŒ–ç™¾åˆ†æ¯”(%)'].round(2)
            
            st.dataframe(display_decrease, use_container_width=True)
            
            # Create bar chart for top decreases
            fig_decrease = go.Figure()
            fig_decrease.add_trace(go.Bar(
                x=display_decrease['è‚¡ç¥¨åç§°'],
                y=display_decrease[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'],
                marker_color='green',
                text=display_decrease[f'{market_value_type}å˜åŒ–(äº¿å…ƒ)'].round(2),
                textposition='auto'
            ))
            fig_decrease.update_layout(
                title=f"{market_value_type}å‡å°‘æœ€å¤šçš„å‰{top_n}åªè‚¡ç¥¨",
                xaxis_title="è‚¡ç¥¨åç§°",
                yaxis_title=f"{market_value_type}å˜åŒ– (äº¿å…ƒ)",
                height=600
            )
            st.plotly_chart(fig_decrease, use_container_width=True)
            
            # Add download buttons for the data
            st.subheader("æ•°æ®ä¸‹è½½")
            
            # Convert to CSV for download
            csv_increase = display_increase.to_csv(index=False)
            csv_decrease = display_decrease.to_csv(index=False)
            
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label=f"ä¸‹è½½{market_value_type}å¢åŠ æœ€å¤šçš„è‚¡ç¥¨æ•°æ®",
                    data=csv_increase,
                    file_name=f"top_increase_{market_value_type}_{start_date_str}_to_{end_date_str}.csv",
                    mime="text/csv"
                )
            with col2:
                st.download_button(
                    label=f"ä¸‹è½½{market_value_type}å‡å°‘æœ€å¤šçš„è‚¡ç¥¨æ•°æ®",
                    data=csv_decrease,
                    file_name=f"top_decrease_{market_value_type}_{start_date_str}_to_{end_date_str}.csv",
                    mime="text/csv"
                )
        except Exception as e:
            error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            st.error(error_msg)
            logging.error(error_msg)
            logging.error(traceback.format_exc())
            st.code(traceback.format_exc())

if __name__ == "__main__":
    main()