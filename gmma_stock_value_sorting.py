import streamlit as st
import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import re
import time
import random
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# Set page layout to wide mode
st.set_page_config(
    page_title="Aè‚¡å¸‚å€¼å˜åŒ–æ’åºå™¨",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# App title and description
st.title("Aè‚¡å¸‚å€¼å˜åŒ–æ’åºå·¥å…·")
st.markdown("""
æ­¤åº”ç”¨ç¨‹åºä½¿ç”¨ akshare æ•°æ®åˆ†æä¸­å›½ A è‚¡è‚¡ç¥¨åœ¨æŒ‡å®šæ—¶é—´åŒºé—´å†…çš„æ€»å¸‚å€¼å˜åŒ–ã€‚
å®ƒä¼šåŸºäºç”¨æˆ·é€‰æ‹©çš„èµ·æ­¢æ—¥æœŸå¹¶å‘æ‰«æå…¨å¸‚åœºï¼Œåˆ—å‡ºæ€»å¸‚å€¼å¢å¹…æœ€å¤§çš„å‰50åªè‚¡ç¥¨ä»¥åŠè·Œå¹…æœ€å¤§çš„å‰50åªè‚¡ç¥¨ã€‚
""")

# Create cache directory if it doesn't exist
cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "cache")
os.makedirs(cache_dir, exist_ok=True)

MAX_WORKERS = min(6, max(2, (os.cpu_count() or 2)))
DEFAULT_LOOKBACK_DAYS = 30
TOP_COUNT = 50
ERROR_LOG_DISPLAY_LIMIT = 100
ERROR_LOG_FILE = os.path.join(cache_dir, "value_sorting_errors.log")
STOCK_LIST_CACHE_FILE = os.path.join(cache_dir, "stock_list.csv")
STOCK_LIST_REFRESH_DAYS = 7
REQUEST_MAX_RETRIES = 3
REQUEST_MIN_INTERVAL = 0.08  # seconds between outbound requests
REQUEST_JITTER = 0.03        # random jitter to avoid fixed pattern
REQUEST_BACKOFF_FACTOR = 1.8
REQUEST_BACKOFF_MAX = 6.0

_request_lock = Lock()
_next_available_time = 0.0

# Cache for stock list to avoid repeated API calls
@st.cache_data(ttl=3600)  # Cache for 1 hour
def get_stock_list():
    """è·å–æ‰€æœ‰æ²ªæ·±Aè‚¡çš„ä»£ç å’Œåç§°ï¼Œå¹¶åœ¨æœ¬åœ°ç¼“å­˜ä¸ƒå¤©"""
    try:
        use_cached_file = False
        if os.path.exists(STOCK_LIST_CACHE_FILE):
            file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(STOCK_LIST_CACHE_FILE))
            if file_age <= timedelta(days=STOCK_LIST_REFRESH_DAYS):
                use_cached_file = True
        if use_cached_file:
            cached_df = pd.read_csv(STOCK_LIST_CACHE_FILE, dtype={"code": str, "name": str})
            cached_df['code'] = cached_df['code'].str.zfill(6)
            return cached_df

        stock_list_df = ak.stock_info_a_code_name()
        if stock_list_df is not None and not stock_list_df.empty:
            stock_list_df['code'] = stock_list_df['code'].astype(str).str.zfill(6)
            try:
                stock_list_df.to_csv(STOCK_LIST_CACHE_FILE, index=False, encoding="utf-8")
            except Exception as write_err:
                append_error_log(f"ä¿å­˜è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥: {write_err}")
        elif os.path.exists(STOCK_LIST_CACHE_FILE):
            # API å¤±è´¥ä½†ä»æœ‰æ—§ç¼“å­˜å¯ç”¨
            cached_df = pd.read_csv(STOCK_LIST_CACHE_FILE, dtype={"code": str, "name": str})
            cached_df['code'] = cached_df['code'].str.zfill(6)
            return cached_df
        return stock_list_df or pd.DataFrame(columns=['code', 'name'])
    except Exception as e:
        append_error_log(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        if os.path.exists(STOCK_LIST_CACHE_FILE):
            try:
                cached_df = pd.read_csv(STOCK_LIST_CACHE_FILE, dtype={"code": str, "name": str})
                cached_df['code'] = cached_df['code'].str.zfill(6)
                return cached_df
            except Exception as read_err:
                append_error_log(f"è¯»å–æœ¬åœ°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥: {read_err}")
        st.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}")
        return pd.DataFrame(columns=['code', 'name'])

def append_error_log(message):
    """å°†é”™è¯¯ä¿¡æ¯å†™å…¥æ—¥å¿—æ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    try:
        with open(ERROR_LOG_FILE, "a", encoding="utf-8") as log_file:
            log_file.write(f"[{timestamp}] {message}\n")
    except Exception:
        pass
    
def acquire_request_slot():
    """Rate limit outbound requests toé¿å…è§¦å‘è¿œç«¯é™æµ"""
    global _next_available_time
    with _request_lock:
        now = time.monotonic()
        wait = _next_available_time - now
        if wait < 0:
            wait = 0.0
        _next_available_time = now + wait + REQUEST_MIN_INTERVAL
    if wait > 0:
        time.sleep(wait)
    if REQUEST_JITTER > 0:
        time.sleep(random.uniform(0, REQUEST_JITTER))
    
def backoff_delay(attempt):
    """Calculate exponential backoff delay for retries"""
    delay = REQUEST_BACKOFF_FACTOR ** attempt
    return min(delay, REQUEST_BACKOFF_MAX)
    
# Helper to normalise Chinese number strings like "123.4äº¿"
def parse_numeric_value(value):
    """å°†å¸¦å•ä½çš„ä¸­æ–‡æ•°å­—å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
    if value is None or (isinstance(value, float) and np.isnan(value)):
        return np.nan
    if isinstance(value, (int, float, np.number)):
        return float(value)
    text = str(value).strip().replace(",", "")
    if not text:
        return np.nan
    # Remove common wrapper characters
    for ch in ("(", ")", "ï¼ˆ", "ï¼‰", " "):
        text = text.replace(ch, "")
    if text in {"", "--", "None"}:
        return np.nan
    suffix_multipliers = [
        ("ä¸‡äº¿å…ƒ", 1e12),
        ("äº¿å…ƒ", 1e8),
        ("äº¿è‚¡", 1e8),
        ("äº¿ä»½", 1e8),
        ("äº¿æ‰‹", 1e8 * 100),
        ("äº¿", 1e8),
        ("ä¸‡è‚¡", 1e4),
        ("ä¸‡ä»½", 1e4),
        ("ä¸‡æ‰‹", 1e4 * 100),
        ("ä¸‡å…ƒ", 1e4),
        ("ä¸‡", 1e4),
        ("åƒè‚¡", 1e3),
        ("åƒä»½", 1e3),
        ("åƒæ‰‹", 1e3 * 100),
        ("ç™¾è‚¡", 1e2),
        ("ç™¾ä»½", 1e2),
        ("ç™¾æ‰‹", 1e2 * 100),
        ("è‚¡", 1.0),
        ("ä»½", 1.0),
        ("æ‰‹", 100.0),
        ("å…ƒ", 1.0)
    ]
    multiplier = 1.0
    for suffix, factor in suffix_multipliers:
        if text.endswith(suffix):
            text = text[:-len(suffix)]
            multiplier = factor
            break
    # Extract numeric component
    match = re.search(r"-?\d+(?:\.\d+)?", text)
    if not match:
        return np.nan
    try:
        return float(match.group()) * multiplier
    except ValueError:
        return np.nan

# Cache stock basic info to avoid repeated API hits
@st.cache_data(ttl=3600)
def get_stock_basic_info(symbol_no_prefix):
    """è·å–å•åªè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯ï¼ˆæ€»è‚¡æœ¬ã€æµé€šè‚¡æœ¬ã€å¸‚å€¼ç­‰ï¼‰"""
    try:
        info_df = ak.stock_individual_info_em(symbol=symbol_no_prefix)
    except Exception:
        return {}
    if info_df is None or info_df.empty:
        return {}
    info_dict = dict(zip(info_df["item"], info_df["value"]))
    return info_dict

# Function to get historical market value data for a stock
@st.cache_data(ttl=900, show_spinner=False)
def get_stock_market_value(symbol, start_date, end_date):
    """è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç»™å®šæ—¥æœŸèŒƒå›´çš„å¸‚å€¼æ•°æ®"""
    try:
        symbol_no_prefix = str(symbol).zfill(6)
        hist_df = None
        last_exception = None
        
        for attempt in range(REQUEST_MAX_RETRIES):
            if attempt:
                time.sleep(backoff_delay(attempt))
            acquire_request_slot()
            try:
                hist_df = ak.stock_zh_a_hist(
                    symbol=symbol_no_prefix,
                    period="daily",
                    start_date=start_date,
                    end_date=end_date,
                    adjust=""
                )
                break
            except Exception as exc:
                last_exception = exc
                continue
        
        if hist_df is None:
            reason = last_exception or "æœªçŸ¥é”™è¯¯"
            append_error_log(
                f"è·å– {symbol_no_prefix} æ•°æ®å¤±è´¥(é‡è¯• {REQUEST_MAX_RETRIES} æ¬¡åæ”¾å¼ƒ): {reason}"
            )
            return None
        
        if hist_df.empty:
            return None
        
        # Ensure we always have a name column for downstream usage
        if 'åç§°' not in hist_df.columns:
            basic_info = get_stock_basic_info(symbol_no_prefix)
            stock_name = basic_info.get('è¯åˆ¸ç®€ç§°') or symbol_no_prefix
            hist_df['åç§°'] = stock_name
        
        # Normalise date column
        hist_df['æ—¥æœŸ'] = pd.to_datetime(hist_df['æ—¥æœŸ'])
        
        # Calculate market value when not provided directly
        has_circ_mv = 'æµé€šå¸‚å€¼' in hist_df.columns
        has_total_mv = 'æ€»å¸‚å€¼' in hist_df.columns
        if not has_circ_mv or not has_total_mv:
            basic_info = get_stock_basic_info(symbol_no_prefix)
            float_shares = parse_numeric_value(basic_info.get('æµé€šè‚¡æœ¬'))
            total_shares = parse_numeric_value(basic_info.get('æ€»è‚¡æœ¬'))
            latest_circ_mv = parse_numeric_value(basic_info.get('æµé€šå¸‚å€¼'))
            latest_total_mv = parse_numeric_value(basic_info.get('æ€»å¸‚å€¼'))
            
            # Use latest market value to back-calc shares if share counts missing
            close_candidates = [col for col in hist_df.columns if any(key in col for key in ['æ”¶ç›˜', 'close'])]
            close_col = None
            if 'æ”¶ç›˜' in hist_df.columns:
                close_col = 'æ”¶ç›˜'
            elif 'æ”¶ç›˜ä»·' in hist_df.columns:
                close_col = 'æ”¶ç›˜ä»·'
            elif close_candidates:
                close_col = close_candidates[0]
            elif 'close' in hist_df.columns:
                close_col = 'close'
            
            if close_col is not None:
                end_price = parse_numeric_value(hist_df.iloc[-1][close_col])
            else:
                end_price = np.nan
            
            if np.isnan(float_shares) and not np.isnan(latest_circ_mv) and end_price not in (None, 0):
                float_shares = latest_circ_mv / end_price if end_price else np.nan
            if np.isnan(total_shares) and not np.isnan(latest_total_mv) and end_price not in (None, 0):
                total_shares = latest_total_mv / end_price if end_price else np.nan
            
            if close_col is not None:
                if not has_circ_mv and not np.isnan(float_shares):
                    hist_df['æµé€šå¸‚å€¼'] = hist_df[close_col].apply(lambda x: parse_numeric_value(x) * float_shares if pd.notna(x) else np.nan)
                    has_circ_mv = True
                if not has_total_mv and not np.isnan(total_shares):
                    hist_df['æ€»å¸‚å€¼'] = hist_df[close_col].apply(lambda x: parse_numeric_value(x) * total_shares if pd.notna(x) else np.nan)
                    has_total_mv = True
        
        for col in ['æµé€šå¸‚å€¼', 'æ€»å¸‚å€¼']:
            if col in hist_df.columns:
                hist_df[col] = hist_df[col].apply(parse_numeric_value)
        
        # Return only necessary columns if market value available
        needed_cols = ['æ—¥æœŸ', 'åç§°']
        if has_circ_mv:
            needed_cols.append('æµé€šå¸‚å€¼')
        if has_total_mv:
            needed_cols.append('æ€»å¸‚å€¼')
        return hist_df[needed_cols]
    except Exception as e:
        append_error_log(f"è·å– {symbol} æ•°æ®å¤±è´¥: {e}")
        return None

# Function to test available AkShare functions for historical data
def test_available_history_functions():
    """æµ‹è¯•å¯ç”¨çš„å†å²æ•°æ®å‡½æ•°"""
    test_stock = "000001"  # å¹³å®‰é“¶è¡Œ
    results = {}
    
    # List of potential functions to try
    functions_to_try = [
        {"name": "stock_zh_a_hist", "params": {"symbol": test_stock, "period": "daily", "start_date": "20230101", "end_date": "20230102", "adjust": ""}},
        {"name": "stock_zh_a_daily", "params": {"symbol": test_stock}},
        {"name": "stock_zh_a_spot_em", "params": {}},
        {"name": "stock_individual_info_em", "params": {"symbol": test_stock}}
    ]
    
    for func in functions_to_try:
        try:
            function_name = func["name"]
            function = getattr(ak, function_name)
            result = function(**func["params"])
            
            if not result.empty:
                # Check if market value data is available
                has_market_value = any('å¸‚å€¼' in col for col in result.columns)
                columns = list(result.columns)
                
                results[function_name] = {
                    "status": "success",
                    "has_market_value": has_market_value,
                    "columns": columns,
                    "sample": result.head(1).to_dict('records')[0] if not result.empty else {}
                }
            else:
                results[function_name] = {
                    "status": "empty_result",
                    "has_market_value": False,
                    "columns": []
                }
        except Exception as e:
            results[function_name] = {
                "status": "error",
                "error": str(e)
            }
    
    return results

# Function to add exchange prefix to stock code
def add_exchange_prefix(code):
    """æ ¹æ®è‚¡ç¥¨ä»£ç æ·»åŠ äº¤æ˜“æ‰€å‰ç¼€"""
    code = str(code).zfill(6)
    if code.startswith(('6', '688', '900')):
        return f"sh{code}"
    else:
        return f"sz{code}"

# Function to get market value for specific dates
def get_market_value_for_dates(symbol, start_date, end_date):
    """è·å–æŒ‡å®šè‚¡ç¥¨åœ¨èµ·å§‹æ—¥å’Œç»“æŸæ—¥çš„å¸‚å€¼æ•°æ®"""
    try:
        symbol_no_prefix = str(symbol).zfill(6)
        # Get all data in range
        df = get_stock_market_value(symbol, start_date, end_date)
        if df is None or df.empty:
            return None, None, None, None, None, "å†å²è¡Œæƒ…ä¸ºç©º"
        
        # Ensure we have at least one record
        if len(df) < 1:
            return None, None, None, None, None, "å†å²è®°å½•æ•°é‡ä¸è¶³"
        
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        name = df.iloc[-1].get('åç§°', symbol)
        circ_series = df['æµé€šå¸‚å€¼'] if 'æµé€šå¸‚å€¼' in df.columns else pd.Series(dtype=float)
        total_series = df['æ€»å¸‚å€¼'] if 'æ€»å¸‚å€¼' in df.columns else pd.Series(dtype=float)
        
        def extract_first_last(series):
            if series.empty:
                return None, None
            valid = series.dropna()
            if valid.empty:
                return None, None
            first_value = float(valid.iloc[0])
            last_value = float(valid.iloc[-1])
            return first_value, last_value
        
        start_circ_mv, end_circ_mv = extract_first_last(circ_series)
        start_total_mv, end_total_mv = extract_first_last(total_series)
        
        if start_total_mv is None or end_total_mv is None:
            # Attempt to reconstruct total market value from closing price and share count
            close_column_candidates = ["æ”¶ç›˜", "æ”¶ç›˜ä»·", "close", "Close", "æ”¶ç›˜(å…ƒ)", "æ”¶ç›˜ä»·(å…ƒ)", "æ”¶ç›˜ä»·(å…ƒ/è‚¡)"]
            close_col = next((col for col in close_column_candidates if col in df.columns), None)
            if close_col:
                closing_prices = df[close_col].apply(parse_numeric_value)
                basic_info = get_stock_basic_info(symbol_no_prefix)
                total_shares = parse_numeric_value(basic_info.get('æ€»è‚¡æœ¬'))
                if pd.notna(total_shares) and total_shares not in (0, np.nan):
                    reconstructed_total_series = closing_prices * total_shares
                    start_total_mv, end_total_mv = extract_first_last(reconstructed_total_series)
        
        if start_total_mv is None or end_total_mv is None:
            return None, None, None, None, None, "æ— æ³•è·å–æˆ–é‡å»ºæ€»å¸‚å€¼æ•°æ®"
        
        return name, start_circ_mv, end_circ_mv, start_total_mv, end_total_mv, None
    except Exception as e:
        return None, None, None, None, None, f"å¼‚å¸¸: {e}"

# Function to calculate date range formatted for API
def get_formatted_date_range(days_ago):
    """è®¡ç®—ä»å½“å‰æ—¥æœŸå‘å‰æ¨ç®—çš„æ—¥æœŸï¼Œæ ¼å¼åŒ–ä¸ºAPIæ‰€éœ€æ ¼å¼"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days_ago)
    
    # Format dates to YYYYMMDD
    start_date_str = start_date.strftime('%Y%m%d')
    end_date_str = end_date.strftime('%Y%m%d')
    
    return start_date_str, end_date_str

# Function to test API with a single stock
def test_api_connectivity(start_date_str, end_date_str):
    """æµ‹è¯•ä¸APIçš„è¿æ¥å’Œæ•°æ®è·å–"""
    test_stocks = ['000001', '600000']  # Test with both SZ and SH markets
    results = []
    
    # First, test which functions are available
    function_test_results = test_available_history_functions()
    
    # Now test actual data retrieval for specific stocks
    for stock in test_stocks:
        try:
            hist_df = get_stock_market_value(stock, start_date_str, end_date_str)
            
            if hist_df is not None and not hist_df.empty:
                sample_data = hist_df.head(1).to_dict('records')[0]
                results.append({
                    'stock': stock,
                    'status': 'success',
                    'columns': list(hist_df.columns),
                    'sample': sample_data
                })
            else:
                results.append({
                    'stock': stock,
                    'status': 'empty_response',
                    'columns': [],
                    'sample': {}
                })
        except Exception as e:
            results.append({
                'stock': stock,
                'status': 'error',
                'error': str(e),
                'traceback': traceback.format_exc()
            })
    
    return {
        'stock_tests': results,
        'function_tests': function_test_results
    }

# Main functionality
def main():
    # Sidebar options
    st.sidebar.title("åˆ†æè®¾ç½®")
    
    today = datetime.now().date()
    default_start = today - timedelta(days=DEFAULT_LOOKBACK_DAYS)
    
    start_date = st.sidebar.date_input(
        "å¼€å§‹æ—¥æœŸ",
        value=default_start,
        max_value=today
    )
    
    end_date = st.sidebar.date_input(
        "ç»“æŸæ—¥æœŸ",
        value=today,
        min_value=start_date,
        max_value=today
    )
    
    if start_date > end_date:
        st.sidebar.error("ç»“æŸæ—¥æœŸéœ€æ™šäºæˆ–ç­‰äºå¼€å§‹æ—¥æœŸ")
        return
    
    start_date_str = start_date.strftime('%Y%m%d')
    end_date_str = end_date.strftime('%Y%m%d')
    
    
    
    # Start analysis button
    if st.sidebar.button("å¼€å§‹åˆ†æ", type="primary"):
        try:
            # Display selected parameters
            st.subheader("åˆ†æå‚æ•°")
            st.write(f"- æ—¶é—´åŒºé—´: {start_date_str} è‡³ {end_date_str}")
            st.write("- æ’é™¤ ST/*ST è‚¡ç¥¨ä»¥é¿å…å¼‚å¸¸æ•°æ®")
            st.write(f"- å›ºå®šè¾“å‡ºæ€»å¸‚å€¼æ¶¨è·Œæ¦œ TOP/BOTTOM {TOP_COUNT}")
            
            # Get stock list
            with st.spinner("æ­£åœ¨è·å– A è‚¡è‚¡ç¥¨åˆ—è¡¨..."):
                stock_list_df = get_stock_list()
                if stock_list_df.empty:
                    st.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·ç¨åé‡è¯•")
                    return
                stock_list_df['code'] = stock_list_df['code'].astype(str).str.zfill(6)
                stock_list_df = stock_list_df.drop_duplicates(subset=['code'])
                initial_count = len(stock_list_df)
                stock_list_df = stock_list_df[~stock_list_df['name'].astype(str).str.contains('ST', case=False, na=False)]
                removed = initial_count - len(stock_list_df)
                if removed > 0:
                    st.info(f"å·²è‡ªåŠ¨æ’é™¤ {removed} åª ST/*ST è‚¡ç¥¨")
                
                st.success(f"å…±è·å–åˆ° {len(stock_list_df)} åª A è‚¡è‚¡ç¥¨")
            
            if stock_list_df.empty:
                st.warning("ç­›é€‰åæ²¡æœ‰å¯ç”¨è‚¡ç¥¨ï¼Œè¯·è°ƒæ•´æ¡ä»¶åé‡è¯•")
                return
            
            stock_records = stock_list_df.to_dict('records')
            total_stocks = len(stock_records)

            try:
                with open(ERROR_LOG_FILE, "w", encoding="utf-8") as log_file:
                    log_file.write(f"=== å¸‚å€¼æ’åºè¿è¡Œå¼€å§‹ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                    log_file.write(f"æ—¶é—´åŒºé—´: {start_date_str} è‡³ {end_date_str}\n")
                    log_file.write(f"è‚¡ç¥¨æ€»æ•°: {total_stocks}\n")
            except Exception:
                pass
            
            progress_bar = st.progress(0.0)
            status_text = st.empty()
            results = []
            error_logs = []
            
            def process_stock(record):
                code = str(record.get('code')).zfill(6)
                fallback_name = record.get('name') or code
                try:
                    name, _, _, start_total_mv, end_total_mv, reason = get_market_value_for_dates(
                        code, start_date_str, end_date_str
                    )
                    stock_name = name or fallback_name
                    if reason:
                        message = f"è‚¡ç¥¨ {code} ({stock_name}) æ€»å¸‚å€¼æ•°æ®ç¼ºå¤±: {reason}"
                        append_error_log(message)
                        return None, message
                    change = end_total_mv - start_total_mv
                    if pd.notna(start_total_mv) and start_total_mv != 0:
                        change_percent = change / start_total_mv * 100
                    else:
                        change_percent = np.nan
                    return {
                        "code": code,
                        "name": stock_name,
                        "start_total_mv": float(start_total_mv),
                        "end_total_mv": float(end_total_mv),
                        "total_mv_change": float(change),
                        "total_mv_change_percent": float(change_percent) if not pd.isna(change_percent) else np.nan
                    }, None
                except Exception as exc:
                    message = f"è‚¡ç¥¨ {code} ({fallback_name}) å¼‚å¸¸: {exc}"
                    append_error_log(message)
                    return None, message
            
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                future_to_record = {
                    executor.submit(process_stock, record): record for record in stock_records
                }
                for idx, future in enumerate(as_completed(future_to_record), start=1):
                    record = future_to_record[future]
                    code = str(record.get('code')).zfill(6)
                    fallback_name = record.get('name') or code
                    try:
                        data, error = future.result()
                        if data:
                            results.append(data)
                        if error:
                            error_logs.append(error)
                            append_error_log(error)
                    except Exception as exc:
                        message = f"è‚¡ç¥¨ {code} ({fallback_name}) çº¿ç¨‹å¼‚å¸¸: {exc}"
                        error_logs.append(message)
                        append_error_log(message)
                    progress_bar.progress(min(idx / total_stocks, 1.0))
                    status_text.text(
                        f"å·²å¤„ç†: {idx}/{total_stocks} | æœ‰æ•ˆ: {len(results)} | é”™è¯¯: {len(error_logs)}"
                    )
            
            progress_bar.progress(1.0)
            
            with st.expander("é”™è¯¯æ—¥å¿— (å±•å¼€æŸ¥çœ‹è¯¦æƒ…)", expanded=False):
                if error_logs:
                    st.write(f"å¤„ç†è¿‡ç¨‹ä¸­é‡åˆ° {len(error_logs)} ä¸ªå¼‚å¸¸ï¼š")
                    for i, log in enumerate(error_logs[:ERROR_LOG_DISPLAY_LIMIT], start=1):
                        st.text(f"{i}. {log}")
                    remaining = len(error_logs) - ERROR_LOG_DISPLAY_LIMIT
                    if remaining > 0:
                        st.text(f"... è¿˜æœ‰ {remaining} æ¡é”™è¯¯æœªæ˜¾ç¤º")
                    st.caption(f"å®Œæ•´é”™è¯¯è¯¦æƒ…å·²å†™å…¥ {ERROR_LOG_FILE}")
                else:
                    st.write("å¤„ç†è¿‡ç¨‹æœªå‘ç°é”™è¯¯")
            
            if not results:
                st.error("æœªèƒ½è·å–æœ‰æ•ˆæ•°æ®ï¼Œè¯·å°è¯•å…¶ä»–æ—¶é—´åŒºé—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
                return
            
            results_df = pd.DataFrame(results)
            if results_df.empty:
                st.error("æš‚æ— å¯ç”¨çš„å¸‚å€¼å˜åŒ–ç»“æœ")
                return
            
            available_count = len(results_df)
            st.info(f"æˆåŠŸæ”¶é›†äº† {available_count} åªè‚¡ç¥¨çš„æ€»å¸‚å€¼æ•°æ®")
            
            top_k = min(TOP_COUNT, available_count)
            if top_k == 0:
                st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”¨äºæ’åå±•ç¤º")
                return
            
            top_increase = results_df.nlargest(top_k, 'total_mv_change').copy()
            top_decrease = results_df.nsmallest(top_k, 'total_mv_change').copy()
            
            for df in (top_increase, top_decrease):
                df['start_total_mv_äº¿'] = df['start_total_mv'] / 1e8
                df['end_total_mv_äº¿'] = df['end_total_mv'] / 1e8
                df['change_total_mv_äº¿'] = df['total_mv_change'] / 1e8
                df['change_percent'] = df['total_mv_change_percent']
            
            display_columns = [
                'code', 'name', 'start_total_mv_äº¿', 'end_total_mv_äº¿', 'change_total_mv_äº¿', 'change_percent'
            ]
            
            display_increase = top_increase[display_columns].copy()
            display_increase.columns = [
                'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)', 'ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)', 'æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)', 'å˜åŒ–ç™¾åˆ†æ¯”(%)'
            ]
            display_increase['èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)'] = display_increase['èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)'].round(2)
            display_increase['ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)'] = display_increase['ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)'].round(2)
            display_increase['æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)'] = display_increase['æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)'].round(2)
            display_increase['å˜åŒ–ç™¾åˆ†æ¯”(%)'] = display_increase['å˜åŒ–ç™¾åˆ†æ¯”(%)'].round(2)
            
            display_decrease = top_decrease[display_columns].copy()
            display_decrease.columns = [
                'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)', 'ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)', 'æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)', 'å˜åŒ–ç™¾åˆ†æ¯”(%)'
            ]
            display_decrease['èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)'] = display_decrease['èµ·å§‹æ€»å¸‚å€¼(äº¿å…ƒ)'].round(2)
            display_decrease['ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)'] = display_decrease['ç»“æŸæ€»å¸‚å€¼(äº¿å…ƒ)'].round(2)
            display_decrease['æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)'] = display_decrease['æ€»å¸‚å€¼å˜åŒ–(äº¿å…ƒ)'].round(2)
            display_decrease['å˜åŒ–ç™¾åˆ†æ¯”(%)'] = display_decrease['å˜åŒ–ç™¾åˆ†æ¯”(%)'].round(2)
            
            st.subheader(f"æ€»å¸‚å€¼å¢åŠ æœ€å¤šçš„å‰ {top_k} åªè‚¡ç¥¨")
            st.dataframe(display_increase, use_container_width=True)
            
            st.subheader(f"æ€»å¸‚å€¼å‡å°‘æœ€å¤šçš„å‰ {top_k} åªè‚¡ç¥¨")
            st.dataframe(display_decrease, use_container_width=True)
            
            st.subheader("æ•°æ®ä¸‹è½½")
            csv_increase = display_increase.to_csv(index=False)
            csv_decrease = display_decrease.to_csv(index=False)
            col1, col2 = st.columns(2)
            with col1:
                st.download_button(
                    label="ä¸‹è½½æ€»å¸‚å€¼å¢åŠ æ¦œå•",
                    data=csv_increase,
                    file_name=f"top_increase_total_mv_{start_date_str}_to_{end_date_str}.csv",
                    mime="text/csv"
                )
            with col2:
                st.download_button(
                    label="ä¸‹è½½æ€»å¸‚å€¼å‡å°‘æ¦œå•",
                    data=csv_decrease,
                    file_name=f"top_decrease_total_mv_{start_date_str}_to_{end_date_str}.csv",
                    mime="text/csv"
                )
        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.code(traceback.format_exc())

if __name__ == "__main__":
    main()
